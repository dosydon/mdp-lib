#ifndef MDPLIB_PROBLEM_H
#define MDPLIB_PROBLEM_H

#include <list>
#include "state.h"
#include "action.h"
#include "heuristic.h"
#include "util/rational.h"

/**
 * An abstract class for Stochastic Shortest Path Problem objects.
 */
class Problem
{
protected:
    /**
     * The initial state for the problem.
     */
    State* s0;

    /**
     * Discount factor.
     */
    Rational gamma_;

    /**
     * A list of all the possible actions in this problem.
     */
    std::list<Action *> actions_;

    /**
     * An internal structure to store all states that are generated by calls to the
     * transition function.
     */
    StateSet states_;

    /**
     * A heuristic that estimates the cost to reach a goal from any state.
     */
    Heuristic* heuristic_ = nullptr;

public:
    /**
     * Goal check.
     *
     * Checks if the state given as parameter is a goal or not.
     *
     * @return true if the given state is a goal.
     */
    virtual bool goal(State *s) const =0;

    /**
     * Transition function for the problem.
     *
     * Returns a list with all successors of the state given as the first parameter
     * when the action given as the second parameter is applied.
     *
     * @return A list of succcessors of the given state after applying the given action.
     */
    virtual std::list<Successor> transition(State *s, Action *a) =0;

    /**
     * Cost function for the problem.
     *
     * Returns the cost of applying the action given as the second parameter to the
     * state given as the first parameter.
     *
     * @return The cost of applying action the given action to the given state.
     */
    virtual Rational cost(State *s, Action *a) const =0;

    /**
     * Applicability check.
     *
     * Checks if the action given as the second parameter is applicable to the
     * state given as the first parameter.
     *
     * @return true if the given action can be applied to the given state.
     */
    virtual bool applicable(State *s, Action *a) const =0;

    /**
     * Initial state for this problem.
     *
     * @return The initial state of this problem.
     */
    virtual State* initialState() const
    {
        return s0;
    }

    /**
    * Generates all states that can be reached from s0 and stores them.
    */
    virtual void generateAll() { }

    /**
     * If a state equal to the given state has already been stored, it returns
     * the expanded state. Otherwise, it stores the state first and the returns it.
     *
     * This method relies on the equals() and hashValue() methods of the State class.
     *
     * @param s A state used as a model of an internal state to be returned.
     * @return The state stored internally that equals the given state.
     */
    State *getState(State *s)
    {
        bool check = states_.insert(s).second;
        State *ret = *states_.find(s);
        // the void cast is used to check if the pointers point to the same object
        if ((void *) ret != (void *) s && !check)
            delete s;    // another state was already stored, get rid of the state used to find it
        return ret;
    }

    /**
     * Returns the set containing all states generated so far by calls to getState.
     *
     * @return The states generated so far.
     */
    StateSet& states()
    {
        return states_;
    }

    /**
     * Returns the list of actions in this problem.
     */
    std::list<Action*>& actions()
    {
        return actions_;
    }

    /**
     * Returns the discount factor.
     */
    Rational gamma()
    {
        return gamma_;
    }

    /**
     * Returns the heuristic used for this problem.
     */
    Heuristic* heuristic()
    {
        return heuristic_;
    }

    /**
     Sets the heuristic to use for this problem.
     */
    void setHeuristic(Heuristic* heuristic)
    {
        heuristic_ = heuristic;
    }
};

#endif // MDPLIB_PROBLEM_H
